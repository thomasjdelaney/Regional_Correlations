\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{cohen}
\citation{jun}
\@writefile{toc}{\contentsline {section}{\numberline {1}Motivation}{2}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Effect of binning}{2}{subsection.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Regional Spike Correlation \& Mutual Information distributions}{2}{subsection.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Data}{2}{section.2}}
\citation{cohen}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Stimulus}{3}{subsection.2.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methods}{3}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Binning data}{3}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Geometric Mean}{3}{subsection.3.2}}
\newlabel{sec:geometric_mean}{{3.2}{3}{Geometric Mean}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Finding a suitable time bin width}{3}{subsection.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Surface showing the geometric mean of two numbers $x$ and $y$ (i.e. $\sqrt  {xy}$) as they each vary from $0$ to $50$.\relax }}{4}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:geometric_mean}{{1}{4}{Surface showing the geometric mean of two numbers $x$ and $y$ (i.e. $\sqrt {xy}$) as they each vary from $0$ to $50$.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Correlation coefficients}{4}{subsection.3.4}}
\newlabel{eq:dist_pearsons_corr}{{2}{4}{Correlation coefficients}{equation.3.2}{}}
\citation{shannon}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Spike Count Correlation, $r_{SC}$}{5}{subsubsection.3.4.1}}
\newlabel{sec:spike_count_correlation}{{3.4.1}{5}{Spike Count Correlation, $r_{SC}$}{subsubsection.3.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Signal Correlation, $r_{signal}$}{5}{subsubsection.3.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.3}Separating Correlations \& Anti-correlations}{5}{subsubsection.3.4.3}}
\newlabel{sec:corr_anti_corr}{{3.4.3}{5}{Separating Correlations \& Anti-correlations}{subsubsection.3.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Mutual Information}{5}{subsection.3.5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.1}Entropy $H(X)$}{5}{subsubsection.3.5.1}}
\newlabel{entropy}{{5}{5}{Entropy $H(X)$}{equation.3.5}{}}
\newlabel{joint_entropy}{{6}{5}{Entropy $H(X)$}{equation.3.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.2}Maximum entropy limit}{6}{subsubsection.3.5.2}}
\newlabel{sec:entropy_limit}{{3.5.2}{6}{Maximum entropy limit}{subsubsection.3.5.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.3}Mutual Information $I(X;Y)$}{6}{subsubsection.3.5.3}}
\newlabel{eq:mutual_info_intuitive}{{8}{6}{Mutual Information $I(X;Y)$}{equation.3.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Entropy Limit:} The uppper limit on entropy of binned spike count data as a function of the maximum observed spike count. The orange line is the analytical maximum. The blue line is the entropy of samples with $N=1000$ data points taken from the discrete uniform distribution.\relax }}{7}{figure.caption.3}}
\newlabel{fig:entropy_limit}{{2}{7}{\textbf {Entropy Limit:} The uppper limit on entropy of binned spike count data as a function of the maximum observed spike count. The orange line is the analytical maximum. The blue line is the entropy of samples with $N=1000$ data points taken from the discrete uniform distribution.\relax }{figure.caption.3}{}}
\newlabel{eq:mutual_info_useful}{{10}{7}{Mutual Information $I(X;Y)$}{equation.3.10}{}}
\newlabel{eq:mutual_info_log}{{11}{7}{Mutual Information $I(X;Y)$}{equation.3.11}{}}
\citation{ince}
\citation{strong}
\citation{treves}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.4}Symmetric Uncertainty $U(X;Y)$}{8}{subsubsection.3.5.4}}
\newlabel{eq:symmetric_uncertainty}{{13}{8}{Symmetric Uncertainty $U(X;Y)$}{equation.3.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.5}Measuring entropies the mutual information}{8}{subsubsection.3.5.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Kolmogorov-Smirnov Statistical Test}{8}{subsection.3.6}}
\newlabel{sec:ks_test}{{3.6}{8}{Kolmogorov-Smirnov Statistical Test}{subsection.3.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.1}Empirical distribution function}{8}{subsubsection.3.6.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.2}Two sample K-S test}{8}{subsubsection.3.6.2}}
\citation{cohen}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{9}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Varying bin width}{9}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Spike count correlations at various bin widths}{9}{subsubsection.4.1.1}}
\newlabel{sec:corr_vs_bin_widths}{{4.1.1}{9}{Spike count correlations at various bin widths}{subsubsection.4.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Correlations \& Anti-correlations}{9}{subsubsection.4.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}Signal Correlations}{9}{subsubsection.4.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Spike Count Correlations:} Absolute values of correlation coefficients measured using different time bin widths. Shaded areas indicate standard errors. One figure for each brain region from which data were available. The absolute correlation increases approximately log-linearly with the bin width up to a bin width of $1$ second and levels out somewhat thereafter.\relax }}{10}{figure.caption.4}}
\newlabel{fig:bin_width_vs_correlation_by_region}{{3}{10}{\textbf {Spike Count Correlations:} Absolute values of correlation coefficients measured using different time bin widths. Shaded areas indicate standard errors. One figure for each brain region from which data were available. The absolute correlation increases approximately log-linearly with the bin width up to a bin width of $1$ second and levels out somewhat thereafter.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {Spike Count Correlations:} Absolute values of correlation coefficients measured using different time bin widths. Shaded areas indicate standard errors. One figure for each brain region from which data were available. The absolute correlation increases approximately log-linearly with the bin width up to a bin width of $1$ second and levels out somewhat thereafter.\relax }}{11}{figure.caption.5}}
\newlabel{fig:linear_bin_width_vs_correlation_by_region}{{4}{11}{\textbf {Spike Count Correlations:} Absolute values of correlation coefficients measured using different time bin widths. Shaded areas indicate standard errors. One figure for each brain region from which data were available. The absolute correlation increases approximately log-linearly with the bin width up to a bin width of $1$ second and levels out somewhat thereafter.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textbf  {Spike Count Correlations and Anti-correlations:} Correlation coefficients measured using different time bin widths and separated into positive and negative sets. Shaded areas indicate standard errors. One figure for each brain region from which data were available. The correlations or anti-correlations get stronger as the bin width increases. We see the log linear increase similar to figures \ref  {fig:bin_width_vs_correlation_by_region} and \ref  {fig:linear_bin_width_vs_correlation_by_region}.\relax }}{12}{figure.caption.6}}
\newlabel{fig:corr_anti_corr_by_region}{{5}{12}{\textbf {Spike Count Correlations and Anti-correlations:} Correlation coefficients measured using different time bin widths and separated into positive and negative sets. Shaded areas indicate standard errors. One figure for each brain region from which data were available. The correlations or anti-correlations get stronger as the bin width increases. We see the log linear increase similar to figures \ref {fig:bin_width_vs_correlation_by_region} and \ref {fig:linear_bin_width_vs_correlation_by_region}.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textbf  {Signal Correlations:} Absolute values of signal correlation coefficients measured using different time bin widths. Shaded areas indicate standard errors. One figure for each brain region from which data were available. The signal correlation maintains a fairly constant value across bin widths for most brain regions, with some variations in V1.\relax }}{13}{figure.caption.7}}
\newlabel{fig:linear_bin_width_vs_signal_correlation_by_region}{{6}{13}{\textbf {Signal Correlations:} Absolute values of signal correlation coefficients measured using different time bin widths. Shaded areas indicate standard errors. One figure for each brain region from which data were available. The signal correlation maintains a fairly constant value across bin widths for most brain regions, with some variations in V1.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.4}Mutual Information}{14}{subsubsection.4.1.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.5}Firing rate}{14}{subsubsection.4.1.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Firing rate distributions}{14}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Spike count correlation \& Mutual Information distributions}{14}{subsection.4.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Histograms}{14}{subsubsection.4.3.1}}
\newlabel{sec:histograms}{{4.3.1}{14}{Histograms}{subsubsection.4.3.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Statistical tests}{14}{subsubsection.4.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \textbf  {Mutual Information:} Mutual information measured using different time bin widths. Shaded areas indicate standard errors. One figure for each brain region from which data were available. The mutual information increases as the the bin width increases, reaching a limit of about $3$ bits for bin widths $\geq 1$s.\relax }}{15}{figure.caption.8}}
\newlabel{fig:linear_bin_width_vs_mutual_information_by_region}{{7}{15}{\textbf {Mutual Information:} Mutual information measured using different time bin widths. Shaded areas indicate standard errors. One figure for each brain region from which data were available. The mutual information increases as the the bin width increases, reaching a limit of about $3$ bits for bin widths $\geq 1$s.\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \textbf  {Firing Rate Histograms:} Histograms of the average firing rates within each region. Most neurons have an average firing rate of $< 10$ Hz.\relax }}{16}{figure.caption.9}}
\newlabel{fig:firing_rate_histograms}{{8}{16}{\textbf {Firing Rate Histograms:} Histograms of the average firing rates within each region. Most neurons have an average firing rate of $< 10$ Hz.\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces \textbf  {Spike Count Correlation Histograms:} Histograms of the spike count correlations of $1000$ randomly chosen pairs of neurons from within each region. The time bin width used was $1.0$s. The motor cortex, V1, and striatum all have similar distributions. For these regions the mean $r_{SC}$ is positive, but the median $r_{SC}$ is negative, so their distributions are skewed. The hippocampus is slightly different in that both the median and the mean are positive but close to $0$. The thalamus is different to all the other regions. Both its mean and median are positive and are aprroximately equal to $0.14$.\relax }}{17}{figure.caption.10}}
\newlabel{fig:all_corr_histograms}{{9}{17}{\textbf {Spike Count Correlation Histograms:} Histograms of the spike count correlations of $1000$ randomly chosen pairs of neurons from within each region. The time bin width used was $1.0$s. The motor cortex, V1, and striatum all have similar distributions. For these regions the mean $r_{SC}$ is positive, but the median $r_{SC}$ is negative, so their distributions are skewed. The hippocampus is slightly different in that both the median and the mean are positive but close to $0$. The thalamus is different to all the other regions. Both its mean and median are positive and are aprroximately equal to $0.14$.\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces \textbf  {Mutual Information Histograms:} Histograms of the mutual information of $1000$ randomly chosen pairs of neurons from within each region. The time bin width used was $1.0$s. In motor cortex, V1, and striatum most pairs have mutual information of $\leq 1$ bit. The hippocampus is slightly different more spread out into greater values. In the thalamus, the pairs appear to be more dependent than in the other regions.\relax }}{18}{figure.caption.11}}
\newlabel{fig:all_info_histograms}{{10}{18}{\textbf {Mutual Information Histograms:} Histograms of the mutual information of $1000$ randomly chosen pairs of neurons from within each region. The time bin width used was $1.0$s. In motor cortex, V1, and striatum most pairs have mutual information of $\leq 1$ bit. The hippocampus is slightly different more spread out into greater values. In the thalamus, the pairs appear to be more dependent than in the other regions.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces \textbf  {Symmetric Uncertainty Histograms:} Histograms of the symmetric uncertainty of $1000$ randomly chosen pairs of neurons from within each region. The time bin width used was $1.0$s. The distribution in each region largely reflects the distribution of the mutual information in the same region shown in figure \ref  {fig:all_info_histograms}.\relax }}{19}{figure.caption.12}}
\newlabel{fig:all_symm_unc_histograms}{{11}{19}{\textbf {Symmetric Uncertainty Histograms:} Histograms of the symmetric uncertainty of $1000$ randomly chosen pairs of neurons from within each region. The time bin width used was $1.0$s. The distribution in each region largely reflects the distribution of the mutual information in the same region shown in figure \ref {fig:all_info_histograms}.\relax }{figure.caption.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Spike Count Correlations statistical tests. $\mathbf  {P(H_0)}$ refers to the probability of the null hypothesis, i.e. the p-value.\relax }}{20}{table.caption.13}}
\newlabel{tab:corr_ks_test}{{1}{20}{Spike Count Correlations statistical tests. $\mathbf {P(H_0)}$ refers to the probability of the null hypothesis, i.e. the p-value.\relax }{table.caption.13}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Mutual Information statistical tests. $\mathbf  {P(H_0)}$ refers to the probability of the null hypothesis, i.e. the p-value.\relax }}{20}{table.caption.14}}
\newlabel{tab:info_ks_test}{{2}{20}{Mutual Information statistical tests. $\mathbf {P(H_0)}$ refers to the probability of the null hypothesis, i.e. the p-value.\relax }{table.caption.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}Histograms for strongly responding neurons}{20}{subsubsection.4.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces \textbf  {Spike Count Correlation Histograms, strongly responding cells:} Histograms of the spike count correlations for pairs of strongly responding cells in each region. The time bin width used was $1.0$s. For each region, the stimulus that elicited strong responses from the largest number of neurons was used. We can see that the thalamus has by far the most neurons that meet our criteria for 'strongly responding', i.e. a firing rate of at least $10$ spikes per second.\relax }}{21}{figure.caption.15}}
\newlabel{fig:strong_corr_histograms}{{12}{21}{\textbf {Spike Count Correlation Histograms, strongly responding cells:} Histograms of the spike count correlations for pairs of strongly responding cells in each region. The time bin width used was $1.0$s. For each region, the stimulus that elicited strong responses from the largest number of neurons was used. We can see that the thalamus has by far the most neurons that meet our criteria for 'strongly responding', i.e. a firing rate of at least $10$ spikes per second.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces \textbf  {Mutual Information Histograms, strongly responding cells:} Histograms of the mutual information for pairs of strongly responding cells in each region. The time bin width used was $1.0$s. For each region, the stimulus that elicited strong responses from the largest number of neurons was used. In each region, cells that respond more strongly appear to be more dependent on each other than their weakly responding counterparts.\relax }}{22}{figure.caption.16}}
\newlabel{fig:strong_info_histograms}{{13}{22}{\textbf {Mutual Information Histograms, strongly responding cells:} Histograms of the mutual information for pairs of strongly responding cells in each region. The time bin width used was $1.0$s. For each region, the stimulus that elicited strong responses from the largest number of neurons was used. In each region, cells that respond more strongly appear to be more dependent on each other than their weakly responding counterparts.\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces \textbf  {Symmetric Uncertainty Histograms, strongly responding cells:} Histograms of the symmetric uncertainty for pairs of strongly responding cells in each region. The time bin width used was $1.0$s.\relax }}{23}{figure.caption.17}}
\newlabel{fig:strong_sym_unc_histograms}{{14}{23}{\textbf {Symmetric Uncertainty Histograms, strongly responding cells:} Histograms of the symmetric uncertainty for pairs of strongly responding cells in each region. The time bin width used was $1.0$s.\relax }{figure.caption.17}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Statistical tests comparing the distribution of spike count correlations between pairs of strongly responding neurons to the distribution of spike count correlations using all responding neurons. $\mathbf  {P(H_0)}$ refers to the probability of the null hypothesis, i.e. the p-value.\relax }}{24}{table.caption.18}}
\newlabel{tab:strong_corr_ks_test}{{3}{24}{Statistical tests comparing the distribution of spike count correlations between pairs of strongly responding neurons to the distribution of spike count correlations using all responding neurons. $\mathbf {P(H_0)}$ refers to the probability of the null hypothesis, i.e. the p-value.\relax }{table.caption.18}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Statistical tests comparing the distribution of mutual information measures in strongly responding neurons to the distribution of mutual information in all responding neurons. $\mathbf  {P(H_0)}$ refers to the probability of the null hypothesis, i.e. the p-value.\relax }}{24}{table.caption.19}}
\newlabel{tab:strong_info_ks_test}{{4}{24}{Statistical tests comparing the distribution of mutual information measures in strongly responding neurons to the distribution of mutual information in all responding neurons. $\mathbf {P(H_0)}$ refers to the probability of the null hypothesis, i.e. the p-value.\relax }{table.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Firing rate geometric mean, spike count correlation, mutual information}{24}{subsection.4.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}Regional spike count correlations \& firing rate geometric means}{24}{subsubsection.4.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.2}Regional mutual information \& firing rate geometric means}{24}{subsubsection.4.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces $\mathbf  {r_{SC}}$ \textbf  { vs firing rate geometric mean:} Spike count correlations of pairs of neurons plotted against geometric means of the firing rate of those pairs for each region. Inset, $\rho $ denotes the correlation between these two quantities.\relax }}{25}{figure.caption.20}}
\newlabel{fig:corr_vs_geometric_mean}{{15}{25}{$\mathbf {r_{SC}}$ \textbf { vs firing rate geometric mean:} Spike count correlations of pairs of neurons plotted against geometric means of the firing rate of those pairs for each region. Inset, $\rho $ denotes the correlation between these two quantities.\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.3}Correlation coefficient \& Mutual Information}{26}{subsubsection.4.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces $\mathbf  {I(X;Y)}$ \textbf  { vs firing rate geometric mean:} Mutual information of pairs of neurons plotted against geometric means of the firing rate of those pairs for each region. Inset, $\rho $ denotes the correlation between these two quantities.\relax }}{27}{figure.caption.21}}
\newlabel{fig:info_vs_geometric_mean}{{16}{27}{$\mathbf {I(X;Y)}$ \textbf { vs firing rate geometric mean:} Mutual information of pairs of neurons plotted against geometric means of the firing rate of those pairs for each region. Inset, $\rho $ denotes the correlation between these two quantities.\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces $\mathbf  {r_{SC}}$\textbf  { vs }$\mathbf  {I(X;Y):}$ Correlation coefficients of pairs of neurons plotted against the mutual information of those pairs for each region. Each coloured dot represents a pair. The black lines show the fit of a quadratic polynomial, fitted by minimising the squared error. [\textbf  {Question for Cian:} Should I remove the quadratic lines?]\relax }}{28}{figure.caption.22}}
\newlabel{fig:info_vs_corr}{{17}{28}{$\mathbf {r_{SC}}$\textbf { vs }$\mathbf {I(X;Y):}$ Correlation coefficients of pairs of neurons plotted against the mutual information of those pairs for each region. Each coloured dot represents a pair. The black lines show the fit of a quadratic polynomial, fitted by minimising the squared error. [\textbf {Question for Cian:} Should I remove the quadratic lines?]\relax }{figure.caption.22}{}}
\bibdata{fluorescence_modelling.bbl}
\bibcite{cohen}{1}
\bibcite{jun}{2}
\bibcite{shannon}{3}
\bibcite{ince}{4}
\bibcite{strong}{5}
\bibcite{treves}{6}
