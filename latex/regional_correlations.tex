\documentclass[a4paper,12pt]{article}
\usepackage[utf8x]{inputenc}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[margin=3cm]{geometry}
\usepackage{times}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{hyperref}
\usepackage{setspace}
\usepackage{subcaption}
\usepackage{mathtools}

\pagestyle{fancy}
\fancyhf{}
\lhead{Thomas Delaney}
\rhead{Effect of time bin widths on correlations}
\cfoot{\thepage}

\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{corollary}{Corollary}[section]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\newcommand{\boldnabla}{\mbox{\boldmath$\nabla$}} % to be used in mathmode
\newcommand{\cbar}{\overline{\mathbb{C}}}% to be used in mathmode
\newcommand{\diff}[2]{\frac{d #1}{d #2}}% to be used in mathmode
\newcommand{\difff}[2]{\frac{d^2 #1}{d #2^2}}% to be used in mathmode
\newcommand{\pdiff}[2]{\frac{\partial #1}{\partial #2}} % to be used in mathmode
\newcommand{\pdifff}[2]{\frac{\partial^2 #1}{\partial #2^2}}% to be used in mathmode
\newcommand{\upperth}{$^{\mbox{\footnotesize{th}}}$}%to be used in text mode
\newcommand{\vect}[1]{\mathbf{#1}}% to be used in mathmode
\newcommand{\curl}[1]{\boldnabla \times \vect{#1}} % to be used in mathmode
\newcommand{\divr}[1]{\boldnabla \cdot \vect{#1}} %to be used in mathmode
\newcommand{\modu}[1]{\left| #1 \right|} %to be used in mathmode
\newcommand{\brak}[1]{\left( #1 \right)} % to be used in mathmode
\newcommand{\comm}[2]{\left[ #1 , #2 \right]} %to be used in mathmode
\newcommand{\dop}{\vect{d}} %to be used in mathmode
\newcommand{\cov}{\text{cov}} %to be used in mathmode
\newcommand{\var}{\text{var}} %to be used in mathmode
\newcommand{\mb}{\mathbf} %to be used in mathmode
\newcommand{\bs}{\boldsymbol} %to be used in mathmode
% Title Page
\title{How informative are retinal ganglion cells?}
\author{Thomas Delaney 1330432}

\begin{document}

\tableofcontents

\newpage

\section{Motivation}
\subsection{Effect of binning}
In their review entitled `Measuring and interpreting neural correlations', Cohen and Kohn studied the effects of response strength and time bin width on neural correlation measurement. Using simulated data, they found that correlation measurements taken between weakly responding neurons (i.e. neurons with firing rates of $<10$ spikes per s) will be less than the true pairwise correlation value. They also found that binning the neural spiking data into small time bins can cause the measured correlation to be less than the true value. How small is `small' in this case is related to width of the cross-correlogram of the pair of neurons. But, it was shown in simulation that time bins should be at least $0.1$ seconds wide in order for the measured correlation value to be close to the true correlation value \cite{cohen}.

Our aim here is to measure a big enough sample of pairwise correlations from actual neural data across a selection of time bin widths and compare our results to those of Cohen and Kohn. In order to do this we used data collected using `Neuropixels' probes \cite{jun}. These data are made available publicly online by Dr. Nick Steinmetz \footnote{\url{http://data.cortexlab.net/dualPhase3/}}.

One disadvantage of measuring correlations is that only the linear relationship between the quantities is captured. The mutual information is a model free pairwise measurement that can capture information about linear and non-linear dependencies between quantities. Therefore we also measured the mutual information between pairs of neurons across the same selection of time bin widths. In doing this, we investigated the effect of binning on mutual information measurements.

\subsection{Regional Spike Correlation \& Mutual Information distributions}
We aimed to investigate the distributions of spike count correlations and mutual information within the different brain regions from which we have data available. We measured correlations and mutual information from $1000$ randomly chosen pairs in each region. We made histograms of the results in order to investigate their distributions visually. We used statistical tests to measure the probability of these samples coming from different distributions.

\section{Data}
The recent development of Neuropixels probes has allowed extracellular voltage measurements to be collected from multiple brain regions simultaneously routinely, and in much larger numbers than traditional methods.

Using two probes, spiking activity was simultaneously collected from over $800$ neurons in an awake mouse brain for a period of $84$ minutes. During this period, the mouse was shown various visual stimuli. The $800$ neurons were distributed across $5$ different brain regions: V1, hippocampus, thalamus, motor cortex, and striatum.

The data consist of spike timings and cell/cluster identifiers associating spikes with a certain cell/cluster and a certain time. Each cell/cluster is classified as `good', `multi-unit activity', or `unsorted', referring to the quality of spike sorting. This classification was performed by those who analysed the data. Only the cell/clusters classified as `good' are used in this project.

\subsection{Stimulus}

The stimulus was a full field moving bar grating. There were $17$ stimulus conditions corresponding to $16$ drift directions ($0$ degrees to $337.5$ degrees in $22.5$ degree increments) with $2$Hz temporal frequency and $0.08$ cycles/degree spatial frequency (conditions $1-16$) plus a blank condition ($17$). Each condition was presented $10$ times for $2$ seconds each time, with $1.5$ seconds between trials.

\section{Methods}
\subsection{Binning data}
The data were divided into time bins or various widths ranging from $0.01$ to $2$ seconds. If the bin width was not an integer divisor of the trial period ($2$ seconds), only the bins that lay totally within the trial period were included. For example, when dividing the trials into bins of $0.3$ seconds, the final bin of $0.2$ seconds was excluded. We measured the number of spikes in each time bin.

When performing calculations on the binned data, each bin was treated as an individual measurement. For example, when calculating the spike count correlation coefficient for a given pair of neurons, if the time bin used was $2.0$ seconds, then we had $10$ measurements for each neuron with which to calculate the coefficient. But, if we were using a bin width of $1.0$ second, then we would have $20$ measurements for each neuron.

\subsection{Pairing strongly responding neurons}
A weak response, or low firing rate, has a diminishing effect on measured correlation \cite{cohen}. In order to avoid this effect, we filtered out any neurons with a mean firing rate of less than $10$ spikes per second measured across the $10$ trials. Once these neurons were filtered out, we randomly chose $30$ pairs from all the possible pairs of the remaining neurons. We used these $30$ pairs to calculate $30$ correlation coefficients. We repeated this process for each brain region, and each stimulus condition.

If less than $9$ strongly responding neurons were found it was not possible to make $30$ pairs of strongly responding neurons. In that case, we just used all the strongly responding pairs.

\subsection{Correlation coefficients}
We calculated Pearson's correlation coefficient for pairs of neurons. For jointly distributed random variables $X$ and $Y$, Pearson's correlation coefficient is defined as:
\begin{align}\label{eq:dist_pearsons_corr}
  \rho_{XY} =& \frac{\cov(X,Y)}{\sigma_X \sigma_Y} \\
            =& \frac{E[(X - \mu_X)(Y - \mu_Y)]}{\sigma_X \sigma_Y}
\end{align}
where $E$ denotes the expected value, $\mu$ denotes the mean, and $\sigma$ denotes the standard deviation. The correlation coefficient is a normalised measure of the covariance. It can take values between $1$ (completely correlated) and $-1$ (completely anti-correlated). Two independent variables will have a correlation coefficient of $0$. But, having $0$ correlation does not imply independence.

If we do not know the means and standard deviations required for equation \ref{eq:dist_pearsons_corr}, but we have samples from $X$ and $Y$, Pearson's sample correlation coefficient is defined as:
\begin{align}
  r_{XY} = \frac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^n (x_i - \bar{x})^2}\sqrt{\sum_{i=1}^n (y_i - \bar{y})^2}}
\end{align}
where $\lbrace (x_i, y_i) \rbrace$ for $i \in \lbrace 1, \dots, n \rbrace$ are the paired samples from $X$ and $Y$, and $\bar{x} = \frac{1}{n}\sum_{i=1}^n x_i$, and $\bar{y} = \frac{1}{n}\sum_{i=1}^n y_i$ are the sample means.

In practice we used the python function \texttt{scipy.stats.pearsonr} to calculate the correlation coefficients.

\subsubsection{Spike Count Correlation, $r_{SC}$}\label{sec:spike_count_correlation}
The spike count correlation ($r_{SC}$) of two cells is the correlation between the spike counts of those cells in response to a given stimulus condition.

\subsubsection{Signal Correlation, $r_{signal}$}
The signal correlation of two cells ($r_{signal}$) is the correlation between the mean responses of those cells to each stimulus condition. Note the difference between this and the spike count correlation in section \ref{sec:spike_count_correlation}. The spike count correlation is in response to a given stimulus condition. The signal correlation is the correlation in the mean response to each stimulus condition.

\subsubsection{Separating Correlations \& Anti-correlations}\label{sec:corr_anti_corr}
In order to compare the effect of bin width on measures of negative $r_{SC}$ (anti-correlation) and positive $r_{SC}$ separately, we had to separate correlated and anti-correlated pairs. To do this, we simply measured the mean $r_{SC}$, taking the mean across all the bin widths. If this quantity was positive or zero we regarded the pair as positively correlated. If this quantity was negative we regarded the pair as anti-correlated.

\subsection{Mutual Information}
\subsubsection{Entropy $H(X)$}
The entropy of a random variable $X$, with outcomes $x_1, \dots, x_N$, and corresponding probabilities $p_1, \dots, p_N$ is defined as
\begin{align}\label{entropy}
H(X) = -\sum_{n=1}^N p_n \log _2 p_n
\end{align}
This quantity is also known as the information entropy or the `surprise'. It measures the amount of uncertainty in a random variable. For example, a variable with a probability of $1$ for one outcome, and zero for all other outcomes will have 0 entropy, because it contains no uncertainty. But a variable with a uniform distribution will have maximal entropy as it is the least predictable. This quantity is analogous to the entropy of a physical system \cite{shannon}. Note that any base may be used for the logarithm in equation \ref{entropy}, but using base $2$ means that the quantity will be measured in `bits'.

The joint entropy of two jointly distributed random variables $X$ and $Y$, where $Y$ has outcomes $y_1, \dots, y_M$, is defined as
\begin{align}\label{joint_entropy}
H(X, Y) = -\sum_{n=1}^N \sum_{m=1}^M P(X=x_n, Y=y_m) \log _2 P(X=x_n, Y=y_m)
\end{align}
If $X$ and $Y$ are independent then $H(X,Y) = H(X) + H(Y)$. Otherwise $H(X,Y) \leq H(X) + H(Y)$. When $X$ and $Y$ and completely dependent $H(X,Y) = H(X) = H(Y)$.

The conditional entropy of $Y$ conditioned on $X$ is defined as
\begin{align}
H(Y|X) = -\sum_{n=1}^N \sum_{m=1}^M P(X=x_n, Y=y_m) \log _2 \frac{P(X=x_n, Y=y_m)}{P(X=x_n)}
\end{align}
When $X$ and $Y$ are independent $H(Y|X) = H(Y)$. Intuitively, we learn nothing of $Y$ by knowing $X$, so $Y$ is equally uncertain whether we know $X$ or not. If $Y$ is totally dependent on $X$, then the fraction in the logarithm is $1$, which gives $H(Y|X) = 0$.

These entropy measures are the basis of the mutual information measure.

\subsubsection{Mutual Information $I(X;Y)$}
The mutual information can be defined mathematically in a number of ways, all of which are equivalent. These definitions illustrate the different ways of interpreting the mutual information.

For two jointly distributed random variables $X$ and $Y$, the mutual information $I(X;Y)$ is defined as
\begin{align}\label{eq:mutual_info_intuitive}
I(X;Y)  =& H(Y) - H(Y|X) \\
        =& H(X) - H(X|Y)
\end{align}
Equation \ref{eq:mutual_info_intuitive} fits with the following intuition: The mutual information between $X$ and $Y$ is the reduction in uncertainty about $X$ gained by knowing $Y$, or vice versa. We could also say the mutual information is the amount of information gained about $X$ by knowing $Y$, or vice versa.

Another useful entropy based definition for the mutual information is
\begin{align}
I(X;Y)  =& H(X) + H(Y) - H(X,Y)
\end{align}
This definition is useful because it does not require the calculation of conditional probabilities. This was the form we used when performing calculations.

The mutual information can also be defined in terms of marginal, joint, and conditional distributions. For example,
\begin{align}
I(X;Y)  =& -\sum_{n=1}^N \sum_{m=1}^M P(X=x_n, Y=y_m) \log _2 \frac{P(X=x_n, Y=y_m)}{P(X=x_n) P(Y=y_m)}
\end{align}
Notice that this can be rewritten as a Kullback–Leibler divergence.
\begin{align}
I(X;Y)  =& D_{KL}(P(X,Y)|| P(X)P(Y))
\end{align}
So, we can also think of the mutual information as a measure of the difference between the joint distribution of $X$ and $Y$, and the product of their marginal distributions. Since the product of the marginal distributions is the joint distribution for independent variables, we can think of the mutual information as a measure of the variables' dependence on one another.

\subsubsection{Measuring the mutual information}
In practice, we measured the mutual information using Python and the python package \texttt{pyentropy} \cite{ince}. This also enabled us to use the `quadratic extrapolation' bias correction technique. [citation needed]

\subsection{Kolmogorov-Smirnov Statistical Test}\label{sec:ks_test}
The Kolmogorov-Smirnov test is a statistical test of the equality of one dimensional probability distributions. It can also be used to measure the probability of a sample coming from a reference distribution. We use it to measure the probability of two samples coming from the same distribution. This is more commonly referred to as the `two sample K-S test'.

\subsubsection{Empirical distribution function}
The empirical distribution function is the empirical analogue of the cumulative distribution function. Given some sample $\mathbf{X}$ with $n$ data points, the empirical distribution function is a step function that increases by $1/n$ at each data point value. Mathematically,
\begin{align}
  \hat{F}_{n}(t) = \frac{1}{n} \sum_{i=1}^n \mathbf{1}_{X_i \leq t}
\end{align}
where $\mathbf{1}_{A}$ is the indicator of condition $A$.

Assuming there is some underlying distribution $P(X)$ for the sample, with cumulative distribution function $F(t)$, in the regime where $n \rightarrow \infty$, $\hat{F}_n (t) \rightarrow F(X)$.

\subsubsection{Two sample K-S test}
Given two samples $\mathbf{X}_1$ and $\mathbf{X}_2$, with $n$ and $m$ data points respectively, and with two correponding empirical distribution functions $F_{1,n}(t)$ and $F_{2,m}(t)$, the Kolmogorov-Smirnov statistic is defined as
\begin{align}
  D_{n,m} = \sup_{t} |F_{1,n}(t) - F_{2,m}(t)|
\end{align}
The null hypothesis is that both samples come from the same distribution. This null hypothesis is rejected at confidence level $\alpha$ if
\begin{align}
  D_{n,m} > c(\alpha)\sqrt{\frac{n+m}{nm}}
\end{align}
where
\begin{align}
  c(\alpha) = \sqrt{\frac{-\ln \alpha}{2}}
\end{align}
Note that the two sample K-S test tests if two samples come from the same distribution, but doesn't make any assumptions about the underlying distribution(s).

In practise, we used the python function \texttt{scipy.stats.ks\_2samp} to calculate the K-S test statistic and p-value.

\section{Results}
\subsection{Varying bin width}
In order to investigate the effect of bin width on the various measures we used, we took these measurements using a number of different values for the bin width. We found that the bin width used had an effect on the spike count correlation, and the mutual information.

\subsubsection{Spike count correlations at various bin widths}\label{sec:corr_vs_bin_widths}
For each stimulus condition and each region, we randomly chose $30$ pairs of strongly responding neurons (or chose as many pairs as we could find), measured their absolute spike count correlations ($|r_{SC}|$) and absolute signal correlation ($|r_{signal}|$) using various values for the time bin width and examined the relationship between the coefficients and the bin width. We found that $|r_{SC}|$ increased approximately log-linearly up to a width of $1$s and appeared to level off thereafter, see figure \ref{fig:bin_width_vs_correlation_by_region}, or figure \ref{fig:linear_bin_width_vs_correlation_by_region} for a linear version. This is in agreement with the findings of the simulated experiment in \cite{cohen}. For these figures, we chose the stimulus condition that evoked the strongest response from a given region. This guaranteed us $30$ strongly responding pairs for each region.

\begin{figure}[p]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/bin_width_correlations_hippocampus_15.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/bin_width_correlations_motor_cortex_15.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/bin_width_correlations_striatum_14.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/bin_width_correlations_thalamus_15.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/bin_width_correlations_v1_6.png}
  \end{subfigure}
  \caption{\textbf{Spike Count Correlations:} Absolute values of correlation coefficients measured using different time bin widths. Shaded areas indicate standard errors. One figure for each brain region from which data were available. The absolute correlation increases approximately log-linearly with the bin width up to a bin width of $1$ second and levels out somewhat thereafter.}
  \label{fig:bin_width_vs_correlation_by_region}
\end{figure}

\begin{figure}[p]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/linear_bin_width_correlations_hippocampus_15.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/linear_bin_width_correlations_motor_cortex_15.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/linear_bin_width_correlations_striatum_14.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/linear_bin_width_correlations_thalamus_15.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/linear_bin_width_correlations_v1_6.png}
  \end{subfigure}
  \caption{\textbf{Spike Count Correlations:} Absolute values of correlation coefficients measured using different time bin widths. Shaded areas indicate standard errors. One figure for each brain region from which data were available. The absolute correlation increases approximately log-linearly with the bin width up to a bin width of $1$ second and levels out somewhat thereafter.}
  \label{fig:linear_bin_width_vs_correlation_by_region}
\end{figure}

\subsubsection{Correlations \& Anti-correlations}
We separated the $30$ randomly chosen pairs into correlated and anti-correlated pairs as per section \ref{sec:corr_anti_corr}. We then measured $r_{SC}$ across various bin width values. We found that the positive $r_{SC}$ got more positive as the bin width increased. We also found that the negative $r_{SC}$ got more negative as the bin width increased. Both positive and negative coefficients showed a log-linear increase similar to the absolute spike count correlation coefficients. See figure \ref{fig:corr_anti_corr_by_region}.

\begin{figure}[p]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/linear_bin_width_relative_correlations_hippocampus_15.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/linear_bin_width_relative_correlations_motor_cortex_15.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/linear_bin_width_relative_correlations_striatum_14.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/linear_bin_width_relative_correlations_thalamus_15.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/linear_bin_width_relative_correlations_v1_6.png}
  \end{subfigure}
  \caption{\textbf{Spike Count Correlations and Anti-correlations:} Correlation coefficients measured using different time bin widths and separated into positive and negative sets. Shaded areas indicate standard errors. One figure for each brain region from which data were available. The correlations or anti-correlations get stronger as the bin width increases. We see the log linear increase similar to figures \ref{fig:bin_width_vs_correlation_by_region} and \ref{fig:linear_bin_width_vs_correlation_by_region}.}
  \label{fig:corr_anti_corr_by_region}
\end{figure}

\subsubsection{Signal Correlations}
We found that $|r_{signal}|$ maintained a constant value across different bin widths. This was the case in all regions, with some variations in V1. See figure \ref{fig:linear_bin_width_vs_signal_correlation_by_region}.

\begin{figure}[p]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/signal_linear_bin_width_correlations_hippocampus_0.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/signal_linear_bin_width_correlations_motor_cortex_0.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/signal_linear_bin_width_correlations_striatum_0.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/signal_linear_bin_width_correlations_thalamus_0.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/signal_linear_bin_width_correlations_v1_0.png}
  \end{subfigure}
  \caption{\textbf{Signal Correlations:} Absolute values of signal correlation coefficients measured using different time bin widths. Shaded areas indicate standard errors. One figure for each brain region from which data were available. The signal correlation maintains a fairly constant value across bin widths for most brain regions, with some variations in V1.}
  \label{fig:linear_bin_width_vs_signal_correlation_by_region}
\end{figure}

\subsubsection{Mutual Information}
As in section \ref{sec:corr_vs_bin_widths}, we randomly chose $30$ pairs of strongly responding cells in each region for each stimulus condition and measured the mutual information ($I(X;Y)$) between these pairs using different values for the bin width. As with the spike count correlations, we found that the mutual information increased as the bin width increased up to a bin width of $1$ second, and levelled off thereafter, see figure \ref{fig:linear_bin_width_vs_mutual_information_by_region}.

\begin{figure}[p]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/linear_mutual_info_by_bin_width_hippocampus_15.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/linear_mutual_info_by_bin_width_motor_cortex_15.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/linear_mutual_info_by_bin_width_striatum_14.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/linear_mutual_info_by_bin_width_thalamus_15.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/linear_mutual_info_by_bin_width_v1_6.png}
  \end{subfigure}
  \caption{\textbf{Mutual Information:} Mutual information measured using different time bin widths. Shaded areas indicate standard errors. One figure for each brain region from which data were available. The mutual information increases as the the bin width increases, reaching a limit of about $3$ bits for bin widths $\geq 1$s.}
  \label{fig:linear_bin_width_vs_mutual_information_by_region}
\end{figure}

\subsection{Spike count correlation \& Mutual Information distributions}

\subsubsection{Histograms}\label{sec:histograms}
For each region, we found all of the cells that responded to the stimulus. We randomly selected $1000$ pairs from all possible pairs of these cells, and we measured their pairwise  spike count correlations and mutual information using a bin width of $1.0$s. We created histograms using these data in order to examine the distributions of $r_{SC}$ and $I(X;Y)$ in each region, see figures \ref{fig:all_corr_histograms} and \ref{fig:all_info_histograms}.

\begin{figure}[p]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/all_hippocampus_8_1p0_correlation_histogram.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/all_motor_cortex_8_1p0_correlation_histogram.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/all_striatum_8_1p0_correlation_histogram.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/all_thalamus_8_1p0_correlation_histogram.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/all_v1_8_1p0_correlation_histogram.png}
  \end{subfigure}
  \caption{\textbf{Spike Count Correlation Histograms:} Histograms of the spike count correlations of $1000$ randomly chosen pairs of neurons from within each region. The time bin width used was $1.0$s. The motor cortex, V1, and striatum all have similar distributions. For these regions the mean $r_{SC}$ is positive, but the median $r_{SC}$ is negative, so their distributions are skewed. The hippocampus is slightly different in that both the median and the mean are positive but close to $0$. The thalamus is different to all the other regions. Both its mean and median are positive and are aprroximately equal to $0.14$.}
  \label{fig:all_corr_histograms}
\end{figure}

\begin{figure}[p]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/all_hippocampus_8_1p0_information_histogram.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/all_motor_cortex_8_1p0_information_histogram.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/all_striatum_8_1p0_information_histogram.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/all_thalamus_8_1p0_information_histogram.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/all_v1_8_1p0_information_histogram.png}
  \end{subfigure}
  \caption{\textbf{Mutual Information Histograms:} Histograms of the mutual information of $1000$ randomly chosen pairs of neurons from within each region. The time bin width used was $1.0$s. In motor cortex, V1, and striatum most pairs have mutual information of $\leq 1$ bit. The hippocampus is slightly different more spread out into greater values. In the thalamus, the pairs appear to be more dependent than in the other regions.}
  \label{fig:all_info_histograms}
\end{figure}

\subsubsection{Statistical tests}
We tested if the spike count correlations and mutual information measurements taken from each region could have the same underlying distributions. We used the two sample Kolmogorov-Smirnov test to do this (see section \ref{sec:ks_test}). Given a pair of regions, we tested the samples of $1000$ spike count correlations and mutual information measurements from each region. We did this for all $10$ possible pairs of regions. Results can be seen in tables \ref{tab:corr_ks_test} and \ref{tab:info_ks_test}.

\begin{table}[ht!]
  \begin{center}
    \caption{Spike Count Correlations statistical tests. $\mathbf{P(H_0)}$ refers to the probability of the null hypothesis, i.e. the p-value.}
    \label{tab:corr_ks_test}
    \begin{tabular}{c|c|c|c|c} % <-- Alignments: 1st column left, 2nd middle and 3rd right, with vertical lines in between
      \multicolumn{2}{c|}{\textbf{Regions}} & \textbf{K-S Stat} & $\mathbf{P(H_0)}$ & \textbf{Statistically Significant}\\
      \hline
      Striatum & Thalamus & $0.24$ & $1.0 \times 10^{-25}$ & Yes \\
      Motor cortex & Thalamus & $0.234$ & $1.8 \times 10^{-24}$ & Yes \\
      V1 & Thalamus  & $0.199$ & $8.1 \times 10^{-18}$ & Yes \\
      Hippocampus & Thalamus  & $0.159$ & $1.6 \times 10^{-11}$ & Yes \\
      Striatum & Hippocampus & $0.132$ & $4.5 \times 10^{-8}$ & Yes \\
      Motor cortex & Hippocampus & $0.113$ & $4.9 \times 10^{-6}$ & Yes \\
      V1 & Hippocampus & $0.083$ & $0.001$ & Yes \\
      Striatum & V1 & $0.075$ & $0.006$ & Yes \\
      Motor cortex & V1 & $0.047$ & $0.21$ & No \\
      Motor cortex & Striatum & $0.037$ & $0.49$ & No \\
    \end{tabular}
  \end{center}
\end{table}

\begin{table}[ht!]
  \begin{center}
    \caption{Mutual Information statistical tests. $\mathbf{P(H_0)}$ refers to the probability of the null hypothesis, i.e. the p-value.}
    \label{tab:info_ks_test}
    \begin{tabular}{c|c|c|c|c} % <-- Alignments: 1st column left, 2nd middle and 3rd right, with vertical lines in between
      \multicolumn{2}{c|}{\textbf{Regions}} & \textbf{K-S Stat} & $\mathbf{P(H_0)}$ & \textbf{Statistically Significant}\\
      \hline
      Striatum & Thalamus & $0.72$ & $1.0 \times 10^{-228}$ & Yes \\
      V1 & Thalamus  & $0.63$ & $7.8 \times 10^{-176}$ & Yes \\
      Motor cortex & Thalamus & $0.606$ & $1.1 \times 10^{-161}$ & Yes \\
      Hippocampus & Thalamus  & $0.49$ & $7.2 \times 10^{-106}$ & Yes \\
      Striatum & Hippocampus & $0.318$ & $7.8 \times 10^{-45}$ & Yes \\
      V1 & Hippocampus & $0.191$ & $1.9 \times 10^{-16}$ & Yes \\
      Motor cortex & Striatum & $0.163$ & $4.3 \times 10^{-12}$ & Yes \\
      Motor cortex & Hippocampus & $0.146$ & $6.0 \times 10^{-12}$ & Yes \\
      Striatum & V1 & $0.146$ & $8.7 \times 10^{-10}$ & Yes \\
      Motor cortex & V1 & $0.039$ & $0.43$ & No \\
    \end{tabular}
  \end{center}
\end{table}

\subsubsection{Histograms for strongly responding neurons}
We made histograms similar to those described in section \ref{sec:histograms} for strongly responding cells only. See figures \ref{fig:strong_corr_histograms} and \ref{fig:strong_info_histograms} for the correlation coefficient and mutual information histograms respectively. Note that the number of pairs that were available was significantly less than that for figures \ref{fig:all_corr_histograms} and \ref{fig:all_info_histograms} for most regions. Despite that, the mutual information histograms appear to show that the strongly responding neurons are more dependent than their weakly responding counterparts.

We also performed statistical tests comparing the distribution of correlation coefficients and mutual information measurements in pairs of strongly responding neurons with the distributions of those measurements using the $1000$ randomly selected pairs as mentioned in section \ref{sec:histograms}. We found that some regions have the same distribution of correlation coefficients for both strongly and weakly repsonding neurons. But for mutual information, the strongly repsonding neurons always had a different distribution, see tables \ref{tab:strong_corr_ks_test} and \ref{tab:strong_info_ks_test}.

\begin{figure}[p]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/strong_hippocampus_6_1p0_correlation_histogram.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/strong_motor_cortex_10_1p0_correlation_histogram.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/strong_striatum_14_1p0_correlation_histogram.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/strong_thalamus_8_1p0_correlation_histogram.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/strong_v1_6_1p0_correlation_histogram.png}
  \end{subfigure}
  \caption{\textbf{Spike Count Correlation Histograms, strongly responding cells:} Histograms of the spike count correlations for pairs of strongly responding cells in each region. The time bin width used was $1.0$s. For each region, the stimulus that elicited strong responses from the largest number of neurons was used. We can see that the thalamus has by far the most neurons that meet our criteria for 'strongly responding', i.e. a firing rate of at least $10$ spikes per second.}
  \label{fig:strong_corr_histograms}
\end{figure}

\begin{figure}[p]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/strong_hippocampus_6_1p0_information_histogram.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/strong_motor_cortex_10_1p0_information_histogram.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/strong_striatum_14_1p0_information_histogram.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/strong_thalamus_8_1p0_information_histogram.png}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/strong_v1_6_1p0_information_histogram.png}
  \end{subfigure}
  \caption{\textbf{Mutual Information Histograms, strongly responding cells:} Histograms of the mutual information for pairs of strongly responding cells in each region. The time bin width used was $1.0$s. For each region, the stimulus that elicited strong responses from the largest number of neurons was used. In each region, cells that respond more strongly appear to be more dependent on each other than their weakly responding counterparts.}
  \label{fig:strong_info_histograms}
\end{figure}

\begin{table}[ht!]
  \begin{center}
    \caption{Statistical tests comparing the distribution of spike count correlations between pairs of strongly responding neurons to the distribution of spike count correlations using all responding neurons. $\mathbf{P(H_0)}$ refers to the probability of the null hypothesis, i.e. the p-value.}
    \label{tab:strong_corr_ks_test}
    \begin{tabular}{c|c|c|c} % <-- Alignments: 1st column left, 2nd middle and 3rd right, with vertical lines in between
      \textbf{Region} & \textbf{K-S Stat} & $\mathbf{P(H_0)}$ & \textbf{Statistically Significant}\\
      \hline
      Striatum      & $0.56$    & $2.3 \times 10^{-10}$   & Yes \\
      Motor cortex  & $0.15$    & $2.4 \times 10^{-5}$    & Yes \\
      Thalamus      & $0.054$   & $0.1$                   & No \\
      V1            & $0.19$    & $0.13$                  & No \\
      Hippocampus   & $0.07$    & $0.49$                  & No \\
    \end{tabular}
  \end{center}
\end{table}

\begin{table}[ht!]
  \begin{center}
    \caption{Statistical tests comparing the distribution of mutual information measures in strongly responding neurons to the distribution of mutual information in all responding neurons. $\mathbf{P(H_0)}$ refers to the probability of the null hypothesis, i.e. the p-value.}
    \label{tab:strong_info_ks_test}
    \begin{tabular}{c|c|c|c} % <-- Alignments: 1st column left, 2nd middle and 3rd right, with vertical lines in between
      \textbf{Region} & \textbf{K-S Stat} & $\mathbf{P(H_0)}$ & \textbf{Statistically Significant}\\
      \hline
      Thalamus      & $0.7$   & $2.2 \times 10^{-214}$  & Yes \\
      Motor cortex  & $0.94$  & $9.6 \times 10^{-193}$  & Yes \\
      Hippocampus   & $0.72$  & $9.7 \times 10^{-56}$   & Yes \\
      Striatum      & $0.97$  & $2.7 \times 10^{-30}$   & Yes \\
      V1            & $0.92$  & $1.0 \times 10^{-27}$   & Yes \\
    \end{tabular}
  \end{center}
\end{table}

\section*{Things to discuss with Cian}
\begin{enumerate}
  \item Is all of the above clear?
  \item Are my methods sound?
  \item Could any of my methods be improved?
  \item How can this document be improved? (The figures with the linear x-axis might be better.)
\end{enumerate}


\newpage

\bibliography{fluorescence_modelling.bbl}

\end{document}
